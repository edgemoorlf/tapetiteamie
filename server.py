import os
import json
import struct
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from flask_socketio import SocketIO, emit
from werkzeug.utils import secure_filename
import dashscope
from dashscope.audio.asr import Recognition, RecognitionCallback
from dotenv import load_dotenv
import tempfile
import logging
from threading import Lock

# Âä†ËΩΩÁéØÂ¢ÉÂèòÈáè
load_dotenv()

# ÈÖçÁΩÆÊó•Âøó
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__, static_folder='public', static_url_path='')
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# ÈÖçÁΩÆ
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')
dashscope.api_key = DASHSCOPE_API_KEY

UPLOAD_FOLDER = 'videos'
TEMP_AUDIO_FOLDER = 'temp_audio'
ALLOWED_VIDEO_EXTENSIONS = {'mp4', 'avi', 'mov'}
ALLOWED_AUDIO_EXTENSIONS = {'webm', 'wav', 'mp3', 'pcm'}

# ÂàõÂª∫ÂøÖË¶ÅÁöÑÁõÆÂΩï
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(TEMP_AUDIO_FOLDER, exist_ok=True)
os.makedirs('public', exist_ok=True)

def allowed_file(filename, allowed_extensions):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in allowed_extensions

@app.route('/')
def index():
    return send_from_directory('public', 'index.html')

@app.route('/api/videos', methods=['GET'])
def get_videos():
    """Ëé∑ÂèñÊâÄÊúâËßÜÈ¢ëÂàóË°®ÂèäÂÖ∂Â≠óÂπï"""
    try:
        if not os.path.exists(UPLOAD_FOLDER):
            return jsonify([])

        videos = []
        for filename in os.listdir(UPLOAD_FOLDER):
            if filename.endswith('.mp4'):
                video_info = {
                    'name': filename,
                    'url': f'/videos/{filename}'
                }

                # Check for transcript file (.txt with same name)
                transcript_path = os.path.join(UPLOAD_FOLDER, filename.replace('.mp4', '.txt'))
                if os.path.exists(transcript_path):
                    try:
                        with open(transcript_path, 'r', encoding='utf-8') as f:
                            video_info['transcript'] = f.read().strip()
                            logger.info(f"Loaded transcript for {filename}: {len(video_info['transcript'])} chars")
                    except Exception as e:
                        logger.warning(f"Failed to load transcript for {filename}: {e}")

                videos.append(video_info)

        # Sort videos: introduction.mp4 first, then alphabetically
        def sort_key(video):
            name = video['name'].lower()
            if name == 'introduction.mp4':
                return (0, '')  # First priority
            else:
                return (1, name)  # Alphabetical order

        videos.sort(key=sort_key)

        logger.info(f"Loaded {len(videos)} videos in order: {[v['name'] for v in videos]}")

        return jsonify(videos)
    except Exception as e:
        logger.error(f"Ëé∑ÂèñËßÜÈ¢ëÂàóË°®Â§±Ë¥•: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/videos/<path:filename>')
def serve_video(filename):
    """Êèê‰æõËßÜÈ¢ëÊñá‰ª∂"""
    return send_from_directory(UPLOAD_FOLDER, filename)

@app.route('/api/upload', methods=['POST'])
def upload_video():
    """‰∏ä‰º†ËßÜÈ¢ë"""
    if 'video' not in request.files:
        return jsonify({'error': 'Ê≤°Êúâ‰∏ä‰º†Êñá‰ª∂'}), 400
    
    file = request.files['video']
    if file.filename == '':
        return jsonify({'error': 'Ê≤°ÊúâÈÄâÊã©Êñá‰ª∂'}), 400
    
    if file and allowed_file(file.filename, ALLOWED_VIDEO_EXTENSIONS):
        filename = secure_filename(file.filename)
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)
        
        return jsonify({
            'name': filename,
            'url': f'/videos/{filename}'
        })
    
    return jsonify({'error': '‰∏çÊîØÊåÅÁöÑÊñá‰ª∂Ê†ºÂºè'}), 400

@app.route('/api/speech-to-text', methods=['POST'])
def speech_to_text():
    """‰ΩøÁî® DashScope SDK ËøõË°åËØ≠Èü≥ËØÜÂà´"""
    logger.info("Êî∂Âà∞ËØ≠Èü≥ËØÜÂà´ËØ∑Ê±Ç")
    
    if not DASHSCOPE_API_KEY:
        logger.error("Êú™ÈÖçÁΩÆ DASHSCOPE_API_KEY")
        return jsonify({
            'error': 'Êú™ÈÖçÁΩÆ DASHSCOPE_API_KEY',
            'message': 'ËØ∑Âú® .env Êñá‰ª∂‰∏≠ËÆæÁΩÆ DASHSCOPE_API_KEY',
            'transcript': ''
        }), 500
    
    if 'audio' not in request.files:
        logger.error("Ê≤°ÊúâÊî∂Âà∞Èü≥È¢ëÊñá‰ª∂")
        return jsonify({
            'error': 'Ê≤°ÊúâÈü≥È¢ëÊñá‰ª∂',
            'transcript': ''
        }), 400
    
    audio_file = request.files['audio']
    
    # ‰øùÂ≠ò‰∏¥Êó∂Èü≥È¢ëÊñá‰ª∂
    temp_file = tempfile.NamedTemporaryFile(
        delete=False, 
        suffix='.pcm', 
        dir=TEMP_AUDIO_FOLDER
    )
    temp_filepath = temp_file.name
    temp_file.close()  # ÂÖ≥Èó≠Êñá‰ª∂‰ª•‰æøÂÜôÂÖ•
    
    try:
        # ‰øùÂ≠ò‰∏ä‰º†ÁöÑÈü≥È¢ë
        audio_file.save(temp_filepath)
        file_size = os.path.getsize(temp_filepath)
        logger.info(f"Èü≥È¢ëÊñá‰ª∂Ë∑ØÂæÑ: {temp_filepath}")
        logger.info(f"Èü≥È¢ëÊñá‰ª∂Â§ßÂ∞è: {file_size} bytes")
        
        # ‰ΩøÁî® DashScope SDK ËøõË°åËØÜÂà´
        logger.info("Ê≠£Âú®Ë∞ÉÁî® DashScope ASR API...")
        
        # ÂàõÂª∫ Recognition ÂØπË±°
        recognition = Recognition(
            model='paraformer-realtime-v2',
            format='pcm',
            sample_rate=16000,
            callback=None  # ÂêåÊ≠•Ë∞ÉÁî®
        )
        
        # ËØªÂèñÈü≥È¢ëÊñá‰ª∂ÂÜÖÂÆπÔºà‰Ωú‰∏∫‰∫åËøõÂà∂Êï∞ÊçÆÔºâ
        with open(temp_filepath, 'rb') as f:
            audio_data = f.read()
            logger.info(f"Èü≥È¢ëÊï∞ÊçÆÈïøÂ∫¶: {len(audio_data)} bytes")

        result = recognition.call(temp_filepath)  # ‚úÖ ‰º†ÂÖ• str
        
        logger.info(f"DashScope API ÂìçÂ∫îÁä∂ÊÄÅ: {result.get('status_code', 'unknown')}")
        logger.info(f"DashScope API ÂÆåÊï¥ÂìçÂ∫î: {json.dumps(result, ensure_ascii=False, indent=2)}")
        
        # Ê£ÄÊü•ÊòØÂê¶ÊúâÈîôËØØ
        if isinstance(result, dict) and result.get('status_code') != 200:
            error_msg = result.get('message', 'Êú™Áü•ÈîôËØØ')
            logger.error(f"API ËøîÂõûÈîôËØØ: {error_msg}")
            return jsonify({
                'error': 'API Ë∞ÉÁî®Â§±Ë¥•',
                'message': error_msg,
                'transcript': '',
                'raw': result
            }), 500
        
        # ÊèêÂèñËØÜÂà´ÁªìÊûú
        transcript = extract_transcript(result)
        
        if not transcript or transcript.strip() == '':
            logger.info("ËØÜÂà´ÁªìÊûú‰∏∫Á©∫")
            return jsonify({
                'transcript': '',
                'message': 'Êú™ËÉΩËØÜÂà´Âá∫ËØ≠Èü≥ÔºåËØ∑Á°Æ‰øùÊ∏ÖÊô∞ËØ¥ËØùÂπ∂Èù†ËøëÈ∫¶ÂÖãÈ£é',
                'raw': result
            })
        
        logger.info(f"‚úÖ ËØÜÂà´ÊàêÂäü: {transcript}")
        return jsonify({
            'transcript': transcript.strip(),
            'raw': result
        })
        
    except Exception as e:
        logger.error(f"‚ùå ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•: {str(e)}")
        logger.exception(e)
        
        return jsonify({
            'error': 'ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•',
            'message': str(e),
            'transcript': ''
        }), 500
        
    finally:
        # Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
        try:
            if os.path.exists(temp_filepath):
                os.unlink(temp_filepath)
                logger.info("Â∑≤Âà†Èô§‰∏¥Êó∂Èü≥È¢ëÊñá‰ª∂")
        except Exception as e:
            logger.warning(f"Âà†Èô§‰∏¥Êó∂Êñá‰ª∂Â§±Ë¥•: {e}")

def extract_transcript(result):
    """‰ªé DashScope ÂìçÂ∫î‰∏≠ÊèêÂèñËØÜÂà´ÊñáÊú¨"""
    if not result:
        return ''
    
    try:
        # Á°Æ‰øù result ÊòØÂ≠óÂÖ∏
        if not isinstance(result, dict):
            logger.warning(f"ÂìçÂ∫î‰∏çÊòØÂ≠óÂÖ∏Á±ªÂûã: {type(result)}")
            return ''
        
        # Ê£ÄÊü•ÊòØÂê¶ÊúâÈîôËØØÁä∂ÊÄÅÁ†Å
        status_code = result.get('status_code')
        if status_code and status_code != 200:
            logger.error(f"API ËøîÂõûÈîôËØØÁä∂ÊÄÅÁ†Å: {status_code}")
            return ''
        
        # Â∞ùËØï‰ªé output ‰∏≠ÊèêÂèñ
        output = result.get('output')
        if not output:
            logger.warning("ÂìçÂ∫î‰∏≠Ê≤°Êúâ output Â≠óÊÆµ")
            return ''
        
        # ÊñπÂºè1: output.text (ÊúÄÂ∏∏ËßÅ)
        if isinstance(output, dict) and 'text' in output:
            text = output['text']
            if isinstance(text, str) and text:
                logger.info(f"‰ªé output.text ÊèêÂèñ: {text}")
                return text
        
        # ÊñπÂºè2: output.sentence.text
        if isinstance(output, dict) and 'sentence' in output:
            sentence = output['sentence']
            if isinstance(sentence, dict) and 'text' in sentence:
                text = sentence['text']
                if isinstance(text, str) and text:
                    logger.info(f"‰ªé output.sentence.text ÊèêÂèñ: {text}")
                    return text
        
        # ÊñπÂºè3: output Áõ¥Êé•ÊòØÂ≠óÁ¨¶‰∏≤
        if isinstance(output, str) and output:
            logger.info(f"output Áõ¥Êé•ÊòØÂ≠óÁ¨¶‰∏≤: {output}")
            return output
        
        # ÊñπÂºè4: output.results Êï∞ÁªÑ
        if isinstance(output, dict) and 'results' in output:
            results = output['results']
            if isinstance(results, list) and len(results) > 0:
                texts = []
                for r in results:
                    if isinstance(r, dict):
                        # Â∞ùËØïÂ§ö‰∏™ÂèØËÉΩÁöÑÂ≠óÊÆµÂêç
                        text = (r.get('text') or 
                               r.get('transcription_text') or 
                               r.get('transcript') or
                               '')
                        
                        # Â¶ÇÊûúÊúâÂµåÂ•óÁöÑ sentence
                        if not text and 'sentence' in r:
                            sentence = r['sentence']
                            if isinstance(sentence, dict):
                                text = sentence.get('text', '')
                        
                        if text and isinstance(text, str):
                            texts.append(text)
                
                if texts:
                    combined = ''.join(texts)
                    logger.info(f"‰ªé output.results ÊèêÂèñ: {combined}")
                    return combined
        
        logger.warning(f"Êó†Ê≥ï‰ªéÂìçÂ∫î‰∏≠ÊèêÂèñÊñáÊú¨ÔºåÂìçÂ∫îÁªìÊûÑ: {json.dumps(result, ensure_ascii=False)[:500]}")
        return ''
        
    except Exception as e:
        logger.error(f"ÊèêÂèñÊñáÊú¨Êó∂Âá∫Èîô: {e}")
        logger.exception(e)
        return ''

@app.route('/api/health', methods=['GET'])
def health_check():
    """ÂÅ•Â∫∑Ê£ÄÊü•"""
    return jsonify({
        'status': 'ok',
        'dashscopeConfigured': bool(DASHSCOPE_API_KEY),
        'sdkVersion': dashscope.__version__ if hasattr(dashscope, '__version__') else 'unknown',
        'timestamp': os.popen('date').read().strip()
    })

# ============================================================================
# WebSocket Streaming Implementation
# ============================================================================

class StreamingRecognitionCallback(RecognitionCallback):
    """Callback handler for streaming recognition results"""

    def __init__(self, session_id):
        self.session_id = session_id
        self.partial_results = []
        self.final_result = None

    def on_open(self):
        """Called when recognition stream opens"""
        logger.info(f"[{self.session_id}] Recognition stream opened")
        socketio.emit('recognition_opened', {
            'session_id': self.session_id,
            'status': 'opened'
        })

    def on_event(self, result):
        """Called for each recognition result (partial or final)"""
        try:
            logger.info(f"[{self.session_id}] Recognition event received")

            # Extract transcript from result
            transcript = self._extract_transcript(result)

            if transcript:
                logger.info(f"[{self.session_id}] üìù Transcript: {transcript}")

                # Send partial result to client
                socketio.emit('recognition_result', {
                    'session_id': self.session_id,
                    'transcript': transcript,
                    'is_final': False
                })

                self.partial_results.append(transcript)
                self.final_result = transcript
        except Exception as e:
            logger.error(f"[{self.session_id}] Error in on_event: {e}")
            logger.exception(e)

    def on_complete(self):
        """Called when recognition completes"""
        logger.info(f"[{self.session_id}] Recognition completed")

        # Send final result
        final_transcript = self.final_result or ''
        logger.info(f"[{self.session_id}] ‚úÖ Final transcript: {final_transcript}")

        socketio.emit('recognition_complete', {
            'session_id': self.session_id,
            'transcript': final_transcript,
            'is_final': True
        })

    def on_error(self, result):
        """Called on recognition error"""
        logger.error(f"[{self.session_id}] Recognition error: {result}")
        socketio.emit('recognition_error', {
            'session_id': self.session_id,
            'error': str(result)
        })

    def on_close(self):
        """Called when recognition stream closes"""
        logger.info(f"[{self.session_id}] Recognition stream closed")
        socketio.emit('recognition_closed', {
            'session_id': self.session_id,
            'status': 'closed'
        })

    def _extract_transcript(self, result):
        """Extract transcript from recognition result"""
        try:
            if not result:
                return ''

            # For streaming callbacks, result is RecognitionResult object
            # Try to access output directly
            output = None

            if hasattr(result, 'output'):
                output = result.output
            elif hasattr(result, 'response') and hasattr(result.response, 'output'):
                output = result.response.output
            elif isinstance(result, dict):
                output = result.get('output')

            if not output:
                logger.warning(f"[{self.session_id}] No output in result: {type(result)}, {dir(result)}")
                return ''

            # Try different output formats
            if isinstance(output, dict):
                # Method 1: output.sentence array (for file-based)
                if 'sentence' in output:
                    sentences = output['sentence']
                    if isinstance(sentences, list):
                        texts = []
                        for sentence in sentences:
                            if isinstance(sentence, dict) and 'text' in sentence:
                                texts.append(sentence['text'])
                        if texts:
                            return ''.join(texts)
                    elif isinstance(sentences, dict) and 'text' in sentences:
                        return sentences['text']

                # Method 2: output.text (most common for streaming)
                if 'text' in output and output['text']:
                    return output['text']

            # Method 3: output is string
            if isinstance(output, str):
                return output

            return ''
        except Exception as e:
            logger.error(f"[{self.session_id}] Error extracting transcript: {e}")
            logger.exception(e)
            return ''

# Store active recognition sessions
active_sessions = {}
sessions_lock = Lock()

@socketio.on('connect')
def handle_connect():
    """Handle WebSocket connection"""
    logger.info(f"Client connected: {request.sid}")
    emit('connected', {'session_id': request.sid})

@socketio.on('disconnect')
def handle_disconnect():
    """Handle WebSocket disconnection"""
    logger.info(f"Client disconnected: {request.sid}")

    # Clean up any active recognition session
    with sessions_lock:
        if request.sid in active_sessions:
            try:
                recognition = active_sessions[request.sid]
                recognition.stop()
                del active_sessions[request.sid]
                logger.info(f"Cleaned up recognition session: {request.sid}")
            except Exception as e:
                logger.error(f"Error cleaning up session: {e}")

@socketio.on('start_recognition')
def handle_start_recognition(data=None):
    """Start a new recognition session"""
    session_id = request.sid
    logger.info(f"[{session_id}] Starting recognition session")

    if not DASHSCOPE_API_KEY:
        emit('recognition_error', {
            'error': 'DASHSCOPE_API_KEY not configured'
        })
        return

    try:
        with sessions_lock:
            # Stop any existing session
            if session_id in active_sessions:
                try:
                    active_sessions[session_id].stop()
                except:
                    pass

            # Create new recognition instance with callback
            callback = StreamingRecognitionCallback(session_id)
            recognition = Recognition(
                model='paraformer-realtime-v2',
                format='pcm',
                sample_rate=16000,
                callback=callback
            )

            # Start recognition
            recognition.start()

            # Initialize counters
            recognition._audio_frame_count = 0
            recognition._total_bytes_sent = 0

            # Store session
            active_sessions[session_id] = recognition

            logger.info(f"[{session_id}] Recognition started successfully")
            emit('recognition_started', {
                'session_id': session_id,
                'status': 'started'
            })

    except Exception as e:
        logger.error(f"[{session_id}] Failed to start recognition: {e}")
        logger.exception(e)
        emit('recognition_error', {
            'error': str(e)
        })

@socketio.on('audio_data')
def handle_audio_data(data):
    """Receive and process audio data chunks"""
    session_id = request.sid

    try:
        with sessions_lock:
            if session_id not in active_sessions:
                logger.warning(f"[{session_id}] No active recognition session")
                emit('recognition_error', {
                    'error': 'No active recognition session'
                })
                return

            recognition = active_sessions[session_id]

        # data should be Int16Array sent as array of numbers
        if isinstance(data, dict) and 'audio' in data:
            # Convert Int16 array to bytes
            # Int16 values are -32768 to 32767, need to convert to bytes properly
            int16_array = data['audio']

            # Log first time we receive data
            if not hasattr(recognition, '_first_data_logged'):
                logger.info(f"[{session_id}] First audio data received: {len(int16_array)} samples")
                logger.info(f"[{session_id}] Sample values (first 10): {int16_array[:10]}")
                recognition._first_data_logged = True

            # Pack as little-endian signed 16-bit integers
            audio_bytes = struct.pack(f'<{len(int16_array)}h', *int16_array)
        elif isinstance(data, bytes):
            audio_bytes = data
        else:
            logger.error(f"[{session_id}] Invalid audio data format: {type(data)}")
            return

        # Send audio frame to DashScope
        recognition.send_audio_frame(audio_bytes)

        # Update counters
        recognition._audio_frame_count += 1
        recognition._total_bytes_sent += len(audio_bytes)

        # Log every 50 frames
        if recognition._audio_frame_count % 50 == 0:
            logger.info(f"[{session_id}] Sent {recognition._audio_frame_count} frames, {recognition._total_bytes_sent} bytes total")

        logger.debug(f"[{session_id}] Sent {len(audio_bytes)} bytes to recognition")

    except Exception as e:
        logger.error(f"[{session_id}] Error processing audio data: {e}")
        logger.exception(e)
        emit('recognition_error', {
            'error': str(e)
        })

@socketio.on('stop_recognition')
def handle_stop_recognition(data=None):
    """Stop the recognition session"""
    session_id = request.sid
    logger.info(f"[{session_id}] Stopping recognition session")

    try:
        with sessions_lock:
            if session_id in active_sessions:
                recognition = active_sessions[session_id]

                # Log final stats
                if hasattr(recognition, '_audio_frame_count'):
                    logger.info(f"[{session_id}] Final stats: {recognition._audio_frame_count} frames, {recognition._total_bytes_sent} bytes")

                recognition.stop()
                del active_sessions[session_id]
                logger.info(f"[{session_id}] Recognition stopped successfully")
                emit('recognition_stopped', {
                    'session_id': session_id,
                    'status': 'stopped'
                })
            else:
                logger.warning(f"[{session_id}] No active session to stop")

    except Exception as e:
        logger.error(f"[{session_id}] Error stopping recognition: {e}")
        logger.exception(e)
        emit('recognition_error', {
            'error': str(e)
        })

if __name__ == '__main__':
    print("=" * 60)
    print("üé¨ ËØ≠Èü≥‰∫§‰∫íËßÜÈ¢ëÊí≠ÊîæÂô® - Python ÁâàÊú¨")
    print("=" * 60)
    print()
    print("üìÅ ËßÜÈ¢ëÁõÆÂΩï:", UPLOAD_FOLDER)
    print("üîë DashScope API Key:", '‚úÖ Â∑≤ÈÖçÁΩÆ' if DASHSCOPE_API_KEY else '‚ùå Êú™ÈÖçÁΩÆ')
    
    if DASHSCOPE_API_KEY:
        print(f"   API Key ÂâçÁºÄ: {DASHSCOPE_API_KEY[:10]}...")
    
    try:
        sdk_version = dashscope.__version__ if hasattr(dashscope, '__version__') else 'unknown'
        print(f"üì¶ DashScope SDK ÁâàÊú¨: {sdk_version}")
    except:
        print("üì¶ DashScope SDK ÁâàÊú¨: unknown")
    
    print("üåê ËÆøÈóÆÂú∞ÂùÄ: http://localhost:5001")
    print()
    
    if not DASHSCOPE_API_KEY:
        print("‚ö†Ô∏è  Ë≠¶Âëä: Êú™ÈÖçÁΩÆ DASHSCOPE_API_KEY")
        print("   ËØ∑ÂàõÂª∫ .env Êñá‰ª∂Âπ∂Ê∑ªÂä†:")
        print("   DASHSCOPE_API_KEY=sk-your-key-here")
        print()
        print("   Ëé∑Âèñ API Key: https://dashscope.console.aliyun.com/apiKey")
        print()
    
    print("üí° ÊèêÁ§∫:")
    print("   - ÊµãËØïÈÖçÁΩÆ: python test_dashscope.py")
    print("   - ÊµãËØïÈü≥È¢ë: python test_audio.py <Èü≥È¢ëÊñá‰ª∂>")
    print("   - Êü•ÁúãÊó•Âøó: Áõ¥Êé•Êü•ÁúãÊéßÂà∂Âè∞ËæìÂá∫")
    print()
    print("=" * 60)
    print()

    socketio.run(app, host='0.0.0.0', port=5001, debug=True, allow_unsafe_werkzeug=True)