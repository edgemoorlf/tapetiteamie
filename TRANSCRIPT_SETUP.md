# Video Transcript Setup Guide

## Quick Start

### 1. Create Transcript Files

For each video in `videos/` directory, create a matching `.txt` file:

```
videos/
  â”œâ”€â”€ introduction.mp4   â† Always shown first
  â”œâ”€â”€ introduction.txt   â† Create this
  â”œâ”€â”€ demo.mp4           â† Then alphabetically
  â”œâ”€â”€ demo.txt           â† Create this
  â”œâ”€â”€ tutorial.mp4
  â””â”€â”€ tutorial.txt       â† Create this
```

**Note:** Videos are automatically sorted with `introduction.mp4` first, then alphabetically by filename.

### 2. Transcript File Format

**File name:** Same as video, but with `.txt` extension
**Encoding:** UTF-8
**Content:** Plain text of what is spoken in the video

**Example: `intro.txt`**
```
å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“ã€‚
ä»Šå¤©æˆ‘è¦ä»‹ç»ä¸€ä¸ªæ–°çš„é¡¹ç›®ã€‚
è¿™ä¸ªé¡¹ç›®å¯ä»¥é€šè¿‡è¯­éŸ³æ§åˆ¶è§†é¢‘æ’­æ”¾ã€‚
```

### 3. Restart Server

```bash
python server.py
```

The server will automatically load transcripts when fetching videos.

### 4. Test

Say words from the beginning of the video transcript, and it should match!

**Example:**
- Video: `intro.mp4`
- Transcript starts with: "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“"
- User says: "å¤§å®¶å¥½æ¬¢è¿"
- âœ… Matches `intro.mp4` with high confidence!

## How It Works

### Matching Algorithm

The `TranscriptMatchStrategy` (highest priority) checks:

1. **Beginning Match** (first 100 characters)
   - Splits user speech into words
   - Counts how many words appear in video's first 100 chars
   - If >50% match â†’ High confidence match

2. **Full Transcript Match**
   - Checks entire transcript
   - If >60% of words match â†’ Medium confidence match

### Example

**Video transcript:**
```
å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“ã€‚ä»Šå¤©æˆ‘ä»¬è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨è¯­éŸ³æ§åˆ¶è§†é¢‘æ’­æ”¾ã€‚
è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„åŠŸèƒ½ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚
```

**User says:** "å¤§å®¶å¥½æ¬¢è¿é¢‘é“"

**Matching process:**
```
Words: ["å¤§å®¶å¥½", "æ¬¢è¿", "é¢‘é“"]
Beginning (100 chars): "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“ã€‚ä»Šå¤©æˆ‘ä»¬è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨è¯­éŸ³æ§åˆ¶è§†é¢‘æ’­æ”¾ã€‚"

Matches in beginning:
- "å¤§å®¶å¥½" âœ…
- "æ¬¢è¿" âœ…
- "é¢‘é“" âœ…

Result: 3/3 words matched (100% confidence)
â†’ Match found!
```

## Tips for Creating Good Transcripts

### 1. **Focus on the Beginning**
The first 100 characters are most important:
```
âœ… Good: "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°Pythonæ•™ç¨‹ã€‚ä»Šå¤©æˆ‘ä»¬å­¦ä¹ ..."
âŒ Bad: "å—¯...é‚£ä¸ª...å¥½çš„...å¤§å®¶å¥½..."
```

### 2. **Use Clear, Distinct Words**
```
âœ… Good: "æœºå™¨å­¦ä¹ å…¥é—¨æ•™ç¨‹"
âŒ Bad: "è¿™ä¸ªé‚£ä¸ªæ•™ç¨‹"
```

### 3. **Include Key Topics**
```
âœ… Good: "ä»Šå¤©è®²è§£React Hooksçš„ä½¿ç”¨æ–¹æ³•"
âŒ Bad: "ä»Šå¤©è®²è§£ä¸€ä¸ªæ–°åŠŸèƒ½"
```

### 4. **Remove Filler Words**
```
âœ… Good: "æ¬¢è¿æ¥åˆ°é¢‘é“"
âŒ Bad: "å—¯...æ¬¢è¿...é‚£ä¸ª...æ¥åˆ°é¢‘é“"
```

## Extracting Transcripts from Videos

### Option 1: Automated Script (Recommended)

Use the provided `extract_transcripts.py` script to automatically extract transcripts from all videos:

```bash
# Install ffmpeg first (if not already installed)
# macOS:
brew install ffmpeg

# Ubuntu/Debian:
sudo apt-get install ffmpeg

# Process all videos in videos/ directory
python extract_transcripts.py

# Process specific video
python extract_transcripts.py videos/intro.mp4

# Overwrite existing transcripts
python extract_transcripts.py --force
```

**What it does:**
1. Extracts audio from video using ffmpeg
2. Converts to 16kHz mono WAV format
3. Sends to DashScope ASR for transcription
4. Saves transcript as `.txt` file with same name
5. Cleans up temporary audio files

**Example output:**
```
============================================================
Processing: introduction.mp4
============================================================
  ğŸ“¹ Extracting audio from introduction.mp4...
  âœ… Audio extracted: 2.34 MB
  ğŸ¤ Transcribing audio...
  âœ… Transcription complete: 156 characters
  ğŸ’¾ Saved transcript to: videos/introduction.txt
  ğŸ—‘ï¸  Cleaned up temp audio file
  âœ… Success!
```

### Option 2: Manual Transcription
Watch the video and type what is said.

### Option 3: Use Other ASR Services
- Google Cloud Speech-to-Text
- Azure Speech Services
- AWS Transcribe
- OpenAI Whisper

### Option 4: YouTube Auto-Captions
If video is on YouTube, download auto-generated captions.

## Testing Transcripts

### 1. Check Server Logs

When server starts, you should see:
```
INFO:__main__:Loaded transcript for intro.mp4: 156 chars
INFO:__main__:Loaded transcript for tutorial.mp4: 243 chars
```

### 2. Check Browser Console

When matching occurs:
```
[VideoMatcher] âœ… Match found: {
  transcript: "å¤§å®¶å¥½æ¬¢è¿",
  videoIndex: 0,
  confidence: "100.0%",
  strategy: "Transcript Match",
  reason: "Transcript match: 3/3 words in beginning"
}
```

### 3. Check Transcript Log Panel

In the UI, you'll see:
```
14:23:45 [DashScope] åŒ¹é…ç»“æœ: è§†é¢‘ #1 (Transcript Match, ç½®ä¿¡åº¦: 100.0%)
```

## Troubleshooting

### Transcript Not Loading

**Problem:** Server doesn't log "Loaded transcript"

**Solutions:**
1. Check file name matches exactly (case-sensitive on Linux)
2. Check file encoding is UTF-8
3. Check file is in `videos/` directory
4. Restart server

### Transcript Not Matching

**Problem:** Says words from transcript but doesn't match

**Solutions:**
1. Check if words are in first 100 characters
2. Try saying more words (need >50% match)
3. Check for typos in transcript
4. Check browser console for matching details

### Low Confidence Matches

**Problem:** Matches but with low confidence

**Solutions:**
1. Add more distinctive words to beginning
2. Remove filler words
3. Make transcript more accurate
4. Say more words from the transcript

## Advanced: Programmatic Transcript Generation

### Python Script to Generate Transcripts

```python
import os
from dashscope.audio.asr import Recognition

def transcribe_video(video_path):
    # Extract audio from video
    audio_path = extract_audio(video_path)

    # Use DashScope to transcribe
    recognition = Recognition(
        model='paraformer-realtime-v2',
        format='wav',
        sample_rate=16000,
        callback=None
    )

    result = recognition.call(audio_path)
    transcript = extract_transcript(result)

    # Save transcript
    txt_path = video_path.replace('.mp4', '.txt')
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(transcript)

    print(f"Saved transcript to {txt_path}")

# Process all videos
for video in os.listdir('videos/'):
    if video.endswith('.mp4'):
        transcribe_video(f'videos/{video}')
```

## Example Transcripts

### Example 1: Tutorial Video
**File:** `python-tutorial.txt`
```
å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°Pythonç¼–ç¨‹æ•™ç¨‹ã€‚
ä»Šå¤©æˆ‘ä»¬è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨åˆ—è¡¨å’Œå­—å…¸ã€‚
é¦–å…ˆè®©æˆ‘ä»¬çœ‹çœ‹åˆ—è¡¨çš„åŸºæœ¬æ“ä½œã€‚
åˆ—è¡¨æ˜¯Pythonä¸­æœ€å¸¸ç”¨çš„æ•°æ®ç»“æ„ä¹‹ä¸€ã€‚
```

### Example 2: Introduction Video
**File:** `channel-intro.txt`
```
å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯å°æ˜ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“ã€‚
è¿™ä¸ªé¢‘é“ä¸»è¦åˆ†äº«ç¼–ç¨‹æŠ€æœ¯å’Œé¡¹ç›®å®æˆ˜ã€‚
å¦‚æœä½ å–œæ¬¢æˆ‘çš„å†…å®¹ï¼Œè¯·ç‚¹èµè®¢é˜…ã€‚
```

### Example 3: Demo Video
**File:** `voice-control-demo.txt`
```
è¿™æ˜¯ä¸€ä¸ªè¯­éŸ³æ§åˆ¶è§†é¢‘æ’­æ”¾çš„æ¼”ç¤ºã€‚
ä½ å¯ä»¥é€šè¿‡è¯´è¯æ¥é€‰æ‹©æƒ³çœ‹çš„è§†é¢‘ã€‚
æ¯”å¦‚è¯´"ç¬¬äºŒä¸ª"æˆ–è€…"æ•™ç¨‹"ã€‚
éå¸¸æ–¹ä¾¿ï¼Œè®©æˆ‘ä»¬è¯•è¯•çœ‹ã€‚
```

## Summary

1. âœ… Create `.txt` files with same name as videos
2. âœ… Use UTF-8 encoding
3. âœ… Put important words at the beginning
4. âœ… Remove filler words
5. âœ… Test by saying words from transcript
6. âœ… Check logs for debugging

With transcripts, users can say **what the video is about** instead of just the filename or number!
